data:
  langs:
    - de 
  test_data_root: /home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Evaluation_Datasets/
  train_data_root:
    - data/training_data/multilingual_training_data/onesec+translated_semcor+babel_glosses/de/onesec_de+semcor_de+babelgloss_de.filter.data.xml #/home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Training_Corpora/
  sense_inventory: babelnet
  label_from: training
  gold_id_separator: " "
  outpath: data/models/de_s+g+o
  mfs_file: resources/mfs/mfs_bn.de.bnids.txt
  test_names:
    - wiki_dev_de_wnfilter
    - wiki_test_de_wnfilter
    - semeval2013_de_wnfilter
  max_sentence_token: 30
  sliding_window: 15
  max_segments_in_batch: 2000

model:
  device: cuda 
  model_name: bert-base-multilingual-cased
  learning_rate: 1e-4

training:
  num_epochs: 25 

#wandb:
#  tags:
#    - bert-large-cased
#    - sensekey
