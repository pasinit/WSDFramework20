data:
  langs:
   - en
   - es
   - fr
   - de
   - it
  test_data_root: /home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Evaluation_Datasets/
  train_data_root:
    - data/training_data/multilingual_training_data/translated_semcor/es/semcor.es.data.xml
    - data/training_data/multilingual_training_data/translated_semcor/fr/semcor.fr.data.xml
    - data/training_data/multilingual_training_data/translated_semcor/it/semcor.it.data.xml
    - data/training_data/multilingual_training_data/translated_semcor/de/semcor.de.data.xml
    - data/training_data/multilingual_training_data/translated_semcor/en/semcor.en.data.xml #/home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Training_Corpora/

  gold_id_separator: " "
  outpath: data/models/en+es+de+fr+it/
  label_from: training
  sense_inventory: babelnet
  test_names:
    - senseval2
    - senseval3
    - semeval2007
    - semeval2007_coarse
    - semeval2010
    - semeval2013
    - semeval2015
    - semeval2015_es
    - semeval2013_es
    - semeval2015_it
    - semeval2013_it
    - semeval2013_fr
    - semeval2013_de
    - ALL
  max_sentence_token: 30
  sliding_window: 15
  max_segments_in_batch: 2000

model:
  device: cuda
  model_name: bert-base-multilingual-cased
  learning_rate: 1e-4

training:
  num_epochs: 40

#wandb:
#  tags:
#    - en
#    - bert-large-cased