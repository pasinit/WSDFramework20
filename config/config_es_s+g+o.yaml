data:
  langs:
    - es
  test_data_root: /home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Evaluation_Datasets/
  train_data_root:
    - data/training_data/multilingual_training_data/onesec+translated_semcor+babel_glosses/es/onesec_es+semcor_es+babelgloss_es.filter.data.xml #/home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Training_Corpora/
  sense_inventory: babelnet
  label_from: training
  gold_id_separator: " "
  outpath: data/models/es_s+g+o
  mfs_file: resources/mfs/mfs_bn.es.bnids.txt
  test_names:
    - wiki_dev_es
    - wiki_test_es
    - semeval2013_es_filter
    - semeval2015_es_filter
  max_sentence_token: 30
  sliding_window: 15
  max_segments_in_batch: 2000

model:
  device: cuda
  model_name: bert-base-multilingual-cased
  learning_rate: 1e-4

training:
  num_epochs: 25 

#wandb:
#  tags:
#    - bert-large-cased
#    - sensekey
