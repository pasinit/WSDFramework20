data:
  lazy: True
  langs:
    - en
    - it 
    - es
    - fr
    - de
  #  lemma2synsetpath: /media/tommaso/My Book/factories/output/lemma2bnsynsets.wn_part.en.txt
  test_data_root: /home/tommaso/Documents/data/WSD_Evaluation_Framework_2.0/Evaluation_Datasets/
  train_data_root:
    - data2/training_data/en_training_data/semcor+princeton_glosses/semcor+princeton_glosses_manual.data.xml
    - data2/training_data/en_training_data/onesec_original_data/onesec_testset_instances/OneSeC_EN.data.xml
  sense_inventory: wnoffsets 
  label_from_training: False 
  gold_id_separator: " "
  outpath: data3/models/en_semcor+wng+onesec_wnoffsets_full/
  #mfs_file: resources/mfs/mfs_wn.en.wnoffset.txt
  test_names:
      #- senseval2
      #- senseval3
      #- semeval2007
      #- semeval2007_coarse
      #- semeval2010
      #- semeval2013
      #- semeval2015
      #- ALL
      #- ALL_no_semeval2007
    - wiki_dev_it
    - wiki_test_it
    - semeval2013_it_wnfilter
    - semeval2015_it_wnfilter
    - wiki_dev_es
    - wiki_test_es
    - semeval2013_es_wnfilter
    - semeval2015_es_wnfilter
    - wiki_dev_fr
    - wiki_test_fr
    - semeval2013_fr_wnfilter
    - wiki_dev_de
    - wiki_test_de
    - semeval2013_de_wnfilter
  dev_name: semeval2007

  max_sentence_token: 30
  sliding_window: 15
  max_segments_in_batch: 2000

model:
  device: cuda 
  model_name: bert-base-multilingual-cased
  learning_rate: 1e-4

training:
  num_epochs: 25
  cache_instances: True

#wandb:
#  tags:
#    - bert-large-cased
#    - sensekey
