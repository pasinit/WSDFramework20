data:
  langs:
    - en
    - it
    - es
    - fr
    - de
    - zh
  test_data_root: /home/tommaso/Documents/data/WSD_Evaluation_Framework_3.0/Evaluation_Datasets/
  train_data_root:
    en:
      - /home/tommaso/dev/PycharmProjects/WSDframework/data2/training_data/en_training_data/semcor/semcor.data.xml
  sense_inventory: bnoffsets
  outpath: data4/models/en_semcor_bn/
  test_names:
    en:
      - senseval2
      - senseval3
      - semeval2007
      - semeval2007-coarse
      - semeval2010
      - semeval2013
      - semeval2015
      - ALL-no-semeval2007
    it:
      - semeval2010-it
      - semeval2013-it
      - semeval2015-it
      - wordnet-italian
    es:
      - semeval2013-es
      - semeval2015-es
      - wordnet-spanish
    fr:
      - semeval2013-fr
    de:
      - semeval2013-de
    zh:
      - semeval2010-zh
#    ja:
#      - wordnet-japanese
#    hu:
#      - wordnet-hungarian
#    bg:
#      - wordnet-bulgarian
#    eu:
#      - wordnet-basque
#    ca:
#      - wordnet-catalan
#    ko:
#      - wordnet-korean

  dev_name:
    - en
    - semeval2007

  max_segments_in_batch: 1000
  force_reload: True

model:
  device: cuda
  encoder_name: xlm-roberta-large #bert-base-multilingual-cased
  wsd_model_name: batchnorm_wsd_classifier
  layers_to_use:
    - -1
    - -2
    - -3
    - -4
  cache_instances: True
  finetune_embedder: False

training:
  num_epochs: 50
  gradient_accumulation: 1
  patience: 3
  learning_rate: 1e-4
  gradient_clipping: 1.0
  validation_metric: -loss

wandb:
  metrics_to_report:
    - f1
    - loss
    - epoch
  soft_match: True
